{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP4G+wkBF3E8nK8iyZYHmjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicben2/hgraph2graph/blob/main/Parta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wengong-jin/hgraph2graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsadISerEWt_",
        "outputId": "5d1625e0-8098-4339-d071-03db7d69b6fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hgraph2graph'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 364 (delta 113), reused 92 (delta 92), pack-reused 212 (from 1)\u001b[K\n",
            "Receiving objects: 100% (364/364), 153.12 MiB | 10.36 MiB/s, done.\n",
            "Resolving deltas: 100% (218/218), done.\n",
            "Updating files: 100% (89/89), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hgraph2graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaOma0MHEZBr",
        "outputId": "0677b695-d244-4be1-ca38-6fcfceff2ad0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hgraph2graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPRV4DxXCD_Z",
        "outputId": "4be98919-1f9e-4ac9-a2ac-e3162b380722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit networkx tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import random\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors, Draw\n",
        "from rdkit import DataStructs\n",
        "import sys\n",
        "import os\n",
        "from hgraph import HierVAE, MolGraph, common_atom_vocab, Vocab, PairVocab\n",
        "from hgraph import MoleculeDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.vocab = None\n",
        "    self.atom_vocab = common_atom_vocab\n",
        "    self.rnn_type = 'LSTM'\n",
        "    self.hidden_size = 250\n",
        "    self.embed_size = 250\n",
        "    self.batch_size = 20\n",
        "    self.latent_size = 32\n",
        "    self.depthT = 15\n",
        "    self.depthG = 15\n",
        "    self.diterT = 1\n",
        "    self.diterG = 3\n",
        "    self.dropout = 0.0\n",
        "\n",
        "args = Args()\n",
        "\n",
        "seed = 7\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#vocab\n",
        "vocab_path = 'data/chembl/vocab.txt'\n",
        "vocab = [x.strip(\"\\r\\n \").split() for x in open(vocab_path)]\n",
        "args.vocab = PairVocab(vocab, cuda=(device.type == 'cuda')) # FIX: Explicitly pass cuda argument\n",
        "\n",
        "model_path = 'ckpt/chembl-pretrained/model.ckpt'\n",
        "model = HierVAE(args).to(device)\n",
        "\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "if isinstance(checkpoint, tuple):\n",
        "    model.load_state_dict(checkpoint[0])\n",
        "else:\n",
        "    model.load_state_dict(checkpoint)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qReunSfBECZP",
        "outputId": "c0064b6e-bd14-4614-b59a-2fb21ebee89e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1097598752.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ckpt/chembl-pretrained/model.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHierVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hgraph2graph/hgraph/hgnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHierVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHierMPNEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepthT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepthG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHierMPNDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mditerT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mditerG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtie_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmpn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, avocab, rnn_type, embed_size, hidden_size, depthT, depthG, dropout)\u001b[0m\n\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMolGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOND_LIST\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE_apos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mMolGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_POS\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    401\u001b[0m             )\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cuda_getDeviceCount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             raise AssertionError(\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_smiles = [\n",
        "    #aspirin, caffeine, paracetamol, ethanol, ibuprofen\n",
        "    \"CC(=O)Oc1ccccc1C(=O)O\",\n",
        "    \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\",\n",
        "    \"CC(=O)Nc1ccc(O)cc1\",\n",
        "    \"CCO\",\n",
        "    \"CC(C)Cc1ccc(C(C)C(=O)O)cc1\"\n",
        "]\n",
        "\n",
        "valid_smiles = []\n",
        "for s in input_smiles:\n",
        "    mol = Chem.MolFromSmiles(s)\n",
        "    if mol is not None:\n",
        "        can_smi = Chem.MolToSmiles(mol)\n",
        "        valid_smiles.append(can_smi)\n",
        "    else:\n",
        "        print(f\"Invalid: {s}\")"
      ],
      "metadata": {
        "id": "1cTD9NdzFL0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_molecules(model, smiles_list, vocab, atom_vocab, batch_size=20):\n",
        "    results = []\n",
        "\n",
        "    compatible_smiles = []\n",
        "    for smi in smiles_list:\n",
        "        try:\n",
        "            hmol = MolGraph(smi)\n",
        "            ok = True\n",
        "            for node, attr in hmol.mol_tree.nodes(data=True):\n",
        "                smiles_node = attr['smiles']\n",
        "                ok &= attr['label'] in vocab.vmap\n",
        "                for i, s in attr['inter_label']:\n",
        "                    ok &= (smiles_node, s) in vocab.vmap\n",
        "            if ok:\n",
        "                compatible_smiles.append(smi)\n",
        "            else:\n",
        "                results.append((smi, None, \"Not in vocabulary\"))\n",
        "        except Exception as e:\n",
        "            results.append((smi, None, f\"Error:  {str(e)}\"))\n",
        "\n",
        "    if len(compatible_smiles) == 0:\n",
        "        print(\"No compatible molecules found!\")\n",
        "        return results\n",
        "\n",
        "    dataset = MoleculeDataset(compatible_smiles, vocab, atom_vocab, batch_size)\n",
        "    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=lambda x: x[0])\n",
        "\n",
        "    #reconstruct\n",
        "    with torch.no_grad():\n",
        "        batch_idx = 0\n",
        "        for batch in tqdm(loader, desc=\"Reconstructing\"):\n",
        "            start_idx = batch_size * batch_idx\n",
        "            end_idx = min(batch_size * (batch_idx + 1), len(compatible_smiles))\n",
        "            orig_smiles_batch = compatible_smiles[start_idx: end_idx]\n",
        "\n",
        "            try:\n",
        "                dec_smiles = model.reconstruct(batch)\n",
        "                for orig, dec in zip(orig_smiles_batch, dec_smiles):\n",
        "                    results.append((orig, dec, \"Success\"))\n",
        "            except Exception as e:\n",
        "                for orig in orig_smiles_batch:\n",
        "                    results.append((orig, None, f\"Decode error: {str(e)}\"))\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "SxGvaHw7GfH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tanimoto(smiles1, smiles2, radius=2, nBits=2048):\n",
        "    mol1 = Chem.MolFromSmiles(smiles1)\n",
        "    mol2 = Chem.MolFromSmiles(smiles2)\n",
        "\n",
        "    if mol1 is None or mol2 is None:\n",
        "        return None\n",
        "\n",
        "    fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, radius, nBits=nBits)\n",
        "    fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, radius, nBits=nBits)\n",
        "\n",
        "    return DataStructs.TanimotoSimilarity(fp1, fp2)\n",
        "\n",
        "def get_mol_properties(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    return {\n",
        "        'num_atoms': mol. GetNumAtoms(),\n",
        "        'num_bonds': mol.GetNumBonds(),\n",
        "        'num_rings':  Chem.GetSSSR(mol).__len__(),\n",
        "    }\n",
        "\n",
        "def calculate_error_diagnostics(smiles_in, smiles_out):\n",
        "    mol_in = Chem.MolFromSmiles(smiles_in)\n",
        "    mol_out = Chem.MolFromSmiles(smiles_out)\n",
        "\n",
        "    if mol_in is None or mol_out is None:\n",
        "        return None\n",
        "\n",
        "    props_in = get_mol_properties(smiles_in)\n",
        "    props_out = get_mol_properties(smiles_out)\n",
        "\n",
        "    return {\n",
        "        'delta_atoms': props_out['num_atoms'] - props_in['num_atoms'],\n",
        "        'delta_bonds': props_out['num_bonds'] - props_in['num_bonds'],\n",
        "        'delta_rings': props_out['num_rings'] - props_in['num_rings'],\n",
        "    }\n",
        "\n",
        "def is_exact_match(smiles1, smiles2):\n",
        "    mol1 = Chem.MolFromSmiles(smiles1)\n",
        "    mol2 = Chem.MolFromSmiles(smiles2)\n",
        "\n",
        "    if mol1 is None or mol2 is None:\n",
        "        return False\n",
        "\n",
        "    can1 = Chem.MolToSmiles(mol1)\n",
        "    can2 = Chem. MolToSmiles(mol2)\n",
        "\n",
        "    return can1 == can2\n",
        "\n",
        "def is_valid_molecule(smiles):\n",
        "    if smiles is None or smiles == \"\":\n",
        "        return False\n",
        "    mol = Chem. MolFromSmiles(smiles)\n",
        "    return mol is not None"
      ],
      "metadata": {
        "id": "RCQoT2XEHeqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#results init\n",
        "reconstruction_results = reconstruct_molecules(\n",
        "    model,\n",
        "    valid_smiles,\n",
        "    args.vocab,\n",
        "    args.atom_vocab,\n",
        "    batch_size=args.batch_size\n",
        ")\n",
        "\n",
        "#experiment\n",
        "results_data = []\n",
        "\n",
        "for idx, (smiles_in, smiles_out, status) in enumerate(reconstruction_results):\n",
        "    row = {\n",
        "        'id': idx,\n",
        "        'smiles_in': smiles_in,\n",
        "        'smiles_out': smiles_out if smiles_out else \"\",\n",
        "        'valid_out': 1 if is_valid_molecule(smiles_out) else 0,\n",
        "        'exact_match': 1 if (smiles_out and is_exact_match(smiles_in, smiles_out)) else 0,\n",
        "        'tanimoto':  None,\n",
        "        'delta_atoms': None,\n",
        "        'delta_bonds': None,\n",
        "        'delta_rings': None,\n",
        "        'status': status\n",
        "    }\n",
        "\n",
        "    if is_valid_molecule(smiles_out):\n",
        "        row['tanimoto'] = calculate_tanimoto(smiles_in, smiles_out)\n",
        "\n",
        "        diagnostics = calculate_error_diagnostics(smiles_in, smiles_out)\n",
        "        if diagnostics:\n",
        "            row['delta_atoms'] = diagnostics['delta_atoms']\n",
        "            row['delta_bonds'] = diagnostics['delta_bonds']\n",
        "            row['delta_rings'] = diagnostics['delta_rings']\n",
        "\n",
        "    results_data.append(row)\n",
        "\n",
        "df = pd. DataFrame(results_data)\n",
        "\n",
        "#csv\n",
        "df_csv = df[['id', 'smiles_in', 'smiles_out', 'valid_out', 'exact_match', 'tanimoto', 'delta_atoms', 'delta_bonds', 'delta_rings']].copy()\n",
        "df_csv. to_csv('results.csv', index=False)"
      ],
      "metadata": {
        "id": "WZnfQqtHH6bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summary\n",
        "total_molecules = len(df)\n",
        "valid_outputs = df['valid_out']. sum()\n",
        "exact_matches = df['exact_match'].sum()\n",
        "valid_df = df[df['valid_out'] == 1]\n",
        "\n",
        "print(\"Summary:\")\n",
        "\n",
        "summary_table = pd.DataFrame({\n",
        "    'Metric': [\n",
        "        'Total Molecules Tested',\n",
        "        'Valid Reconstructions',\n",
        "        'Validity Rate (%)',\n",
        "        'Exact Matches',\n",
        "        'Exact Match Accuracy (%)',\n",
        "        'Avg Tanimoto Similarity',\n",
        "        'Lowest Tanimoto Similarity',\n",
        "        'Highest Tanimoto Similarity',\n",
        "    ],\n",
        "    'Value': [\n",
        "        total_molecules,\n",
        "        valid_outputs,\n",
        "        f\"{100 * valid_outputs / total_molecules:.2f}\" if total_molecules > 0 else \"N/A\",\n",
        "        exact_matches,\n",
        "        f\"{100 * exact_matches / total_molecules:.2f}\" if total_molecules > 0 else \"N/A\",\n",
        "        f\"{valid_df['tanimoto'].mean():.4f}\" if len(valid_df) > 0 else \"N/A\",\n",
        "        f\"{valid_df['tanimoto'].min():.4f}\" if len(valid_df) > 0 else \"N/A\",\n",
        "        f\"{valid_df['tanimoto'].max():.4f}\" if len(valid_df) > 0 else \"N/A\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(summary_table.to_string(index=False))\n",
        "print()\n",
        "\n",
        "if len(valid_df) > 0:\n",
        "    print(\"Error diagnostics:\")\n",
        "\n",
        "    error_summary = pd.DataFrame({\n",
        "        'Diagnostic': ['Delta Atoms', 'Delta Bonds', 'Delta Rings'],\n",
        "        'Avg': [\n",
        "            f\"{valid_df['delta_atoms'].mean():.2f}\",\n",
        "            f\"{valid_df['delta_bonds'].mean():.2f}\",\n",
        "            f\"{valid_df['delta_rings'].mean():.2f}\"\n",
        "        ],\n",
        "        'Lowest': [\n",
        "            valid_df['delta_atoms'].min(),\n",
        "            valid_df['delta_bonds'].min(),\n",
        "            valid_df['delta_rings'].min()\n",
        "        ],\n",
        "        'Highest': [\n",
        "            valid_df['delta_atoms'].max(),\n",
        "            valid_df['delta_bonds'].max(),\n",
        "            valid_df['delta_rings'].max()\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    print(error_summary.to_string(index=False))\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "ax1 = axes[0, 0]\n",
        "if len(valid_df) > 0:\n",
        "    ax1.hist(valid_df['tanimoto']. dropna(), bins=20, edgecolor='black', alpha=0.7, color='green')\n",
        "    # ax1.axvline(valid_df['tanimoto'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean:  {valid_df[\"tanimoto\"].mean():.3f}')\n",
        "    # ax1.axvline(valid_df['tanimoto'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {valid_df[\"tanimoto\"].median():.3f}')\n",
        "    # ax1.legend()\n",
        "ax1.set_xlabel('Tanimoto Similarity', fontsize=12)\n",
        "ax1.set_ylabel('Frequency', fontsize=12)\n",
        "ax1.set_title('Tanimoto Similarity Histogram', fontsize=14)\n",
        "ax1.set_xlim(0, 1)\n",
        "\n",
        "def draw_molecules(smiles_in, smiles_out, idx, tanimoto, exact_match):\n",
        "    mol_in = Chem.MolFromSmiles(smiles_in)\n",
        "    mol_out = Chem.MolFromSmiles(smiles_out) if smiles_out else None\n",
        "\n",
        "    fig, axes = plt. subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    # Input molecule\n",
        "    if mol_in:\n",
        "        img_in = Draw.MolToImage(mol_in, size=(300, 300))\n",
        "        axes[0]. imshow(img_in)\n",
        "        axes[0].set_title(f'{smiles_in}', fontsize=8)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Output molecule\n",
        "    if mol_out:\n",
        "        img_out = Draw.MolToImage(mol_out, size=(300, 300))\n",
        "        axes[1].imshow(img_out)\n",
        "        axes[1].set_title(f'{smiles_out}', fontsize=8)\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=14)\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt. tight_layout()\n",
        "    return fig\n",
        "\n",
        "examples = []\n",
        "count = 10\n",
        "\n",
        "for _, row in df.head(count).iterrows():\n",
        "    if row['id'] not in [e['id'] for e in examples]:\n",
        "        examples.append(row)\n",
        "examples = examples[:10]\n",
        "\n",
        "interpretations = []\n",
        "for i, row in enumerate(examples):\n",
        "    smiles_in = row['smiles_in']\n",
        "    smiles_out = row['smiles_out']\n",
        "    exact = row['exact_match']\n",
        "    tanimoto = row['tanimoto']\n",
        "\n",
        "    # Draw comparison\n",
        "    fig = draw_molecules(smiles_in, smiles_out, i, tanimoto, exact)\n",
        "    # plt.savefig(f'example_{i+1}.png', dpi=100, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Generate interpretation\n",
        "    if exact:\n",
        "        interp = f\"The model reconstructed {smiles_in} exactly.\"\n",
        "    elif row['valid_out'] == 0:\n",
        "        interp = f\"The model did not reconstruct {smiles_in} correctly.\"\n",
        "    else:\n",
        "        delta_atoms = row. get('delta_atoms', 0)\n",
        "        delta_bonds = row.get('delta_bonds', 0)\n",
        "        if tanimoto and tanimoto > 0.9:\n",
        "            interp = f\"Almost similar with minor differences.\"\n",
        "        elif tanimoto and tanimoto > 0.7:\n",
        "            interp = f\"Good reconstruction noticeable differences.\"\n",
        "        else:\n",
        "            interp = f\"Example {i+1}:  Significant reconstruction error (Tanimoto={tanimoto:.3f}). Major changes: Δatoms={delta_atoms}, Δbonds={delta_bonds}.\"\n",
        "\n",
        "    print(interp)"
      ],
      "metadata": {
        "id": "E-I1whQpIEUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2xOuv-wK8xG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}